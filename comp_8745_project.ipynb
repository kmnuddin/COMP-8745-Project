{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 8745 Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('training.txt', sep='\\t', header=None,engine='python',error_bad_lines=False, warn_bad_lines=False)\n",
    "data_train.columns = ['Reviews','Ratings']\n",
    "\n",
    "data_test = pd.read_csv('test.txt', sep='\\t',header=None,engine='python',error_bad_lines=False, warn_bad_lines=False)\n",
    "data_test.columns = ['Reviews', 'Ratings']\n",
    "\n",
    "X_train = data_train['Reviews']\n",
    "y_train = data_train['Ratings']\n",
    "\n",
    "X_test = data_test['Reviews']\n",
    "y_test = data_test['Ratings']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of bag of words model using TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecotrizer_train = TfidfVectorizer(stop_words='english')\n",
    "vector_train = vecotrizer.fit_transform(X_train)\n",
    "\n",
    "vecotrizer_test = TfidfVectorizer(stop_words='english')\n",
    "vector_test = vecotrizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [(25, 25), (25, 25, 25), (30,30), (30, 30, 30), (40, 40, 40), (40, 40, 40, 40), (50, 50, 50), (50, 50, 50, 50)] \n",
    "accuracy_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Scores for Test Data for hidden layers (25, 25)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.55      0.62      0.58       199\n",
      "        2.0       0.43      0.32      0.36       200\n",
      "        3.0       0.39      0.47      0.43       200\n",
      "        4.0       0.37      0.46      0.41       200\n",
      "        5.0       0.57      0.40      0.47       200\n",
      "\n",
      "avg / total       0.46      0.45      0.45       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (25, 25, 25)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.64      0.56       199\n",
      "        2.0       0.43      0.41      0.42       200\n",
      "        3.0       0.40      0.41      0.40       200\n",
      "        4.0       0.44      0.41      0.43       200\n",
      "        5.0       0.61      0.49      0.54       200\n",
      "\n",
      "avg / total       0.47      0.47      0.47       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (30, 30)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.55      0.65      0.59       199\n",
      "        2.0       0.46      0.35      0.40       200\n",
      "        3.0       0.41      0.38      0.39       200\n",
      "        4.0       0.38      0.47      0.43       200\n",
      "        5.0       0.53      0.46      0.49       200\n",
      "\n",
      "avg / total       0.47      0.46      0.46       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (30, 30, 30)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.51      0.68      0.58       199\n",
      "        2.0       0.42      0.34      0.38       200\n",
      "        3.0       0.41      0.27      0.32       200\n",
      "        4.0       0.38      0.53      0.44       200\n",
      "        5.0       0.56      0.43      0.49       200\n",
      "\n",
      "avg / total       0.45      0.45      0.44       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (40, 40, 40)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.53      0.67      0.59       199\n",
      "        2.0       0.46      0.31      0.37       200\n",
      "        3.0       0.38      0.29      0.33       200\n",
      "        4.0       0.35      0.50      0.41       200\n",
      "        5.0       0.56      0.47      0.51       200\n",
      "\n",
      "avg / total       0.45      0.45      0.44       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (40, 40, 40, 40)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.58      0.59      0.58       199\n",
      "        2.0       0.43      0.45      0.44       200\n",
      "        3.0       0.42      0.34      0.38       200\n",
      "        4.0       0.40      0.53      0.46       200\n",
      "        5.0       0.50      0.41      0.45       200\n",
      "\n",
      "avg / total       0.47      0.46      0.46       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (50, 50, 50)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.60      0.61      0.60       199\n",
      "        2.0       0.48      0.46      0.47       200\n",
      "        3.0       0.44      0.36      0.40       200\n",
      "        4.0       0.40      0.56      0.47       200\n",
      "        5.0       0.58      0.47      0.52       200\n",
      "\n",
      "avg / total       0.50      0.49      0.49       999\n",
      "\n",
      "--------- Scores for Test Data for hidden layers (50, 50, 50, 50)---------\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.61      0.62       199\n",
      "        2.0       0.45      0.38      0.41       200\n",
      "        3.0       0.38      0.42      0.40       200\n",
      "        4.0       0.39      0.60      0.48       200\n",
      "        5.0       0.57      0.32      0.41       200\n",
      "\n",
      "avg / total       0.48      0.46      0.46       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 8):\n",
    "    nn = MLPClassifier(hidden_layer_sizes=hidden_layers[i], learning_rate_init=0.01)\n",
    "    nn.fit(vector_train, y_train)\n",
    "    y_pred = nn.predict(vector_test)\n",
    "    accuracy_scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    print('--------- Scores for Test Data for hidden layers {}---------'.format(hidden_layers[i]))\n",
    "    print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.50      0.65      0.57       199\n",
      "        2.0       0.49      0.33      0.39       200\n",
      "        3.0       0.43      0.41      0.42       200\n",
      "        4.0       0.44      0.52      0.48       200\n",
      "        5.0       0.65      0.59      0.62       200\n",
      "\n",
      "avg / total       0.50      0.50      0.50       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(vector_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(vector_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.54      0.76      0.64       199\n",
      "        2.0       0.56      0.40      0.46       200\n",
      "        3.0       0.46      0.38      0.42       200\n",
      "        4.0       0.47      0.50      0.48       200\n",
      "        5.0       0.62      0.62      0.62       200\n",
      "\n",
      "avg / total       0.53      0.53      0.52       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(vector_train, y_train)\n",
    "\n",
    "y_pred = lgr.predict(vector_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.57      0.51      0.54       199\n",
      "        2.0       0.42      0.42      0.42       200\n",
      "        3.0       0.39      0.39      0.39       200\n",
      "        4.0       0.41      0.37      0.39       200\n",
      "        5.0       0.52      0.65      0.57       200\n",
      "\n",
      "avg / total       0.46      0.47      0.46       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "adb = AdaBoostClassifier()\n",
    "adb.fit(vector_train, y_train)\n",
    "\n",
    "y_pred = adb.predict(vector_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.00      0.00      0.00       199\n",
      "        2.0       0.00      0.00      0.00       200\n",
      "        3.0       0.00      0.00      0.00       200\n",
      "        4.0       0.20      1.00      0.33       200\n",
      "        5.0       0.00      0.00      0.00       200\n",
      "\n",
      "avg / total       0.04      0.20      0.07       999\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1000, kernel='poly', degree=20)\n",
    "svc.fit(vector_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(vector_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
